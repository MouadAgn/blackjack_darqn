# ğŸƒ Blackjack Atari Agent - DARQN + Attention

Ce projet implÃ©mente un agent d'Apprentissage par Renforcement Profond (Deep RL) capable de jouer au Blackjack sur l'environnement Atari (`ALE/Blackjack-v5`) de Gymnasium.

L'architecture utilisÃ©e est un **DARQN (Deep Attention Recurrent Q-Network)**. Elle est conÃ§ue pour traiter des informations visuelles partielles et sÃ©quentielles, ce qui est idÃ©al pour le Blackjack oÃ¹ l'agent doit :
1. **Voir** les cartes (Vision via CNN).
2. **Se souvenir** des cartes prÃ©cÃ©dentes (MÃ©moire via LSTM).
3. **Se focaliser** sur les zones importantes de l'Ã©cran (MÃ©canisme d'Attention).

## ğŸ“‚ Structure du Projet

L'organisation des fichiers suit une architecture modulaire :

```text
blackjack_darqn/
â”‚
â”œâ”€â”€ checkpoints/             # Dossier de sauvegarde des modÃ¨les (.pth)
â”œâ”€â”€ logs/                    # Logs pour TensorBoard (optionnel)
â”‚
â”œâ”€â”€ src/                     # Code source principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model.py             # Architecture DARQN (CNN + Attention + LSTM)
â”‚   â”œâ”€â”€ memory.py            # Replay Buffer SÃ©quentiel (gÃ¨re les sÃ©quences temporelles)
â”‚   â”œâ”€â”€ agent.py             # Logique d'apprentissage (Loss, Backprop, Target Update)
â”‚   â””â”€â”€ utils.py             # Wrappers d'environnement (Preprocessing Atari)
â”‚
â”œâ”€â”€ config.py                # HyperparamÃ¨tres (Learning rate, Batch size, Gamma...)
â”œâ”€â”€ main.py                  # Script pour lancer l'entraÃ®nement
â”œâ”€â”€ test.py                  # Script pour tester et visualiser (GIF avec Heatmap)
â”œâ”€â”€ requirements.txt         # DÃ©pendances Python
â””â”€â”€ README.md                # Documentation du projet

âš™ï¸ Installation
1. PrÃ©requis
Assurez-vous d'avoir Python 3.8+ installÃ©.

2. Installation des dÃ©pendances
Installez les bibliothÃ¨ques nÃ©cessaires, y compris les ROMs Atari :

Bash

pip install -r requirements.txt
Contenu du requirements.txt suggÃ©rÃ© :

Plaintext

gymnasium[atari, accept-rom-license]
torch
torchvision
numpy
opencv-python
imageio
3. PrÃ©paration des dossiers
CrÃ©ez les dossiers pour stocker les sauvegardes si ce n'est pas fait :

Bash

mkdir checkpoints
mkdir logs
ğŸš€ Utilisation
1. EntraÃ®nement de l'Agent (main.py)
Pour lancer l'apprentissage depuis zÃ©ro. L'agent va explorer l'environnement, remplir sa mÃ©moire et apprendre via le DARQN.

Bash

python main.py
Les modÃ¨les seront sauvegardÃ©s automatiquement dans checkpoints/ tous les X Ã©pisodes (ex: model_100.pth).

Note : L'entraÃ®nement sur pixels est long. Laissez tourner plusieurs heures pour obtenir des rÃ©sultats probants.

2. Test et Visualisation (test.py)
Ce script charge un modÃ¨le entraÃ®nÃ©, joue une partie et gÃ©nÃ¨re un GIF montrant ce que l'IA "regarde" grÃ¢ce Ã  la carte d'attention.

Ouvrez test.py.

Modifiez la ligne de chargement avec votre fichier .pth :

Python

# Exemple
run_test("checkpoints/model_1000.pth")
Lancez le script :

Bash

python test.py
Le rÃ©sultat sera sauvegardÃ© dans le fichier blackjack_attention.gif.